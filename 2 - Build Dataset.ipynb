{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "differential-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os.path\n",
    "import requests\n",
    "import shutil\n",
    "import time\n",
    "from spotify_api import SpotifyAPI\n",
    "from config import client_id, client_secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-direction",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = SpotifyAPI(client_id, client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-rwanda",
   "metadata": {},
   "source": [
    "Find the playlist unique SpotifyID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify.search('Most%Popular%Songs', search_type = 'playlist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-bubble",
   "metadata": {},
   "source": [
    "## Fetch data from spotify API\n",
    "\n",
    "Build a JSON file with the following data:\n",
    "\n",
    "<ul>\n",
    "<li>artist_id</li>\n",
    "<li>artist_name</li>\n",
    "<li>album_id</li>\n",
    "<li>album_name</li>\n",
    "<li>album_popularity</li>\n",
    "<li>genres [list]</li>\n",
    "<li>album_url</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-citizen",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_id = '4o8NBsWreC3OnKePUYw0dg'\n",
    "dataset_name = \"data_full_64.txt\"\n",
    "dataset_path = \".\\\\data\\\\\"\n",
    "\n",
    "data = {}\n",
    "id = 0\n",
    "offset = 0\n",
    "\n",
    "while True:\n",
    "    cnt = 0\n",
    "    r = spotify.get_playlist_items(playlist_id,\n",
    "                                   'items(track(name,artists(id),id,album(id)))',\n",
    "                                   100,\n",
    "                                   offset, \n",
    "                                   'playlists')\n",
    "    \n",
    "    for item in r['items']:\n",
    "        data[id] = {}\n",
    "        artist_id = item['track']['artists'][0]['id'] \n",
    "        album_id = item['track']['album']['id']   \n",
    "        artist = spotify.get_artist(artist_id)\n",
    "        album = spotify.get_album(album_id)\n",
    "\n",
    "        data[id]['artist_id'] = artist_id\n",
    "        data[id]['artist_name'] = artist['name']\n",
    "        data[id]['album_id'] = album_id\n",
    "        data[id]['album_name'] = album['name']\n",
    "        data[id]['album_popularity'] = album['popularity']\n",
    "        data[id]['genres'] = artist['genres']\n",
    "        \n",
    "        for image in album['images']: \n",
    "            if image['height'] == 64:\n",
    "                data[id]['album_url'] = image['url']\n",
    "    \n",
    "        id+=1\n",
    "        cnt+=1\n",
    "        \n",
    "    print(f\"Fetched {id} tracks.\")\n",
    "    \n",
    "    if cnt < 100:\n",
    "        break\n",
    "        \n",
    "    offset += 100\n",
    "        \n",
    "with open(dataset_path + dataset_name, 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-freeze",
   "metadata": {},
   "source": [
    "## Download album cover image\n",
    "\n",
    "The playlist can contain multiple songs from the same album.\n",
    "Using album id, we skip albums already downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-legislation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \".\\\\data\\\\\"\n",
    "image_path = \".\\\\images_64\\\\\"\n",
    "\n",
    "dataset_name = \"data_full_64.txt\"\n",
    "dataset_name_img = \"data_full_64_img.txt\"\n",
    "\n",
    "\n",
    "\n",
    "with open(dataset_path+dataset_name) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "\n",
    "for item in data.keys():\n",
    "    print(item, end= ' ')\n",
    "    downloaded = False\n",
    "    \n",
    "    while not downloaded:\n",
    "        try:\n",
    "            image_url = data[item]['album_url']\n",
    "            album_id = data[item]['album_id'].replace('/','')\n",
    "            filename = image_path + album_id + '.jpg'\n",
    "        except:\n",
    "            break\n",
    "        \n",
    "        if os.path.isfile(filename):\n",
    "            print('File already downloaded.')\n",
    "            break\n",
    "        try:\n",
    "            r = requests.get(image_url, timeout=200, stream = True)\n",
    "            time.sleep(1)\n",
    "            \n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        if r.status_code == 200:\n",
    "            r.raw.decode_content = True\n",
    "            with open(filename,'wb') as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "            downloaded = True\n",
    "            data[item]['filepath'] = filename\n",
    "        else:\n",
    "            print('Image Couldn\\'t be retrieved')\n",
    "\n",
    "\n",
    "with open(dataset_path+dataset_name_img, 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-palmer",
   "metadata": {},
   "source": [
    "## Remove duplicate album entries\n",
    "\n",
    "The final dataset contains unique albums with succesfully downloaded images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_img = \"data_full_64_img.txt\"\n",
    "dataset_name_clean = \"data_full_64_clean.txt\"\n",
    "dataset_path = \".\\\\data\\\\\"\n",
    "\n",
    "\n",
    "with open(dataset_path+dataset_name_img) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "dict_keys_to_del = []\n",
    "\n",
    "for item in data.keys():    \n",
    "    if 'filepath' not in data[item].keys():\n",
    "        dict_keys_to_del.append(item)\n",
    "\n",
    "for item in dict_keys_to_del:\n",
    "    del data[item]\n",
    "    \n",
    "with open(dataset_path+dataset_name_clean, 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name_clean = \"data_full_64_clean.txt\"\n",
    "dataset_path = \".\\\\data\\\\\"\n",
    "\n",
    "with open(dataset_path+dataset_name_clean) as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "print(json.dumps(data, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
